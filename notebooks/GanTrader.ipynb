{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from app.environment.dataprovider import DataProvider\n",
    "from app.preparation.preparator import DataPreparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"using cuda:\", torch.cuda.get_device_name(0))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = os.getenv('TIINGO_API_KEY')\n",
    "days = 5\n",
    "\n",
    "train_start_date = '2000-01-01'\n",
    "train_end_date = '2015-12-31'\n",
    "\n",
    "test_start_date = '2016-01-01'\n",
    "test_end_date = '2020-12-31'\n",
    "\n",
    "provider = DataProvider(apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_buys = None\n",
    "all_none_buys = None\n",
    "columns = ['open', 'high', 'low', 'close']\n",
    "samples_path = f'data/eod/{train_start_date}.{train_end_date}/samples.npz'\n",
    "\n",
    "if not os.path.exists(samples_path):\n",
    "    tickers = provider.tickers.keys()\n",
    "    for ticker in tickers:\n",
    "        company = provider.tickers[ticker]\n",
    "        quotes = provider.load(ticker, train_start_date, train_end_date)\n",
    "        if quotes is None:\n",
    "            continue\n",
    "        quotes[['buy', 'sell']] = DataPreparator.calculate_signals(quotes)\n",
    "        quotes['window'] = \\\n",
    "            DataPreparator.calculate_windows(\n",
    "                quotes,\n",
    "                days=days,\n",
    "                normalize=True,\n",
    "                columns=columns,\n",
    "                adjust=provider.adjust_prices)\n",
    "        buys = DataPreparator.filter_windows_by_signal(quotes, days, 'buy', 'window')\n",
    "        none_buys = DataPreparator.filter_windows_without_signal(quotes, days, ignore_signals=['buy'])\n",
    "        print(f'{ticker:5} - {company:40} - buys: {np.shape(buys)} - non buys: {np.shape(none_buys)}')\n",
    "        if len(buys) > 0:\n",
    "            all_buys = buys if all_buys is None else np.concatenate((all_buys, buys))\n",
    "        if len(none_buys) > 0:\n",
    "            all_none_buys = none_buys if all_none_buys is None else np.concatenate((all_none_buys, none_buys))\n",
    "    print(f'samples - buys: {np.shape(all_buys)} - none buys: {np.shape(all_none_buys)}')\n",
    "    unique_buys, _ = \\\n",
    "        DataPreparator.extract_unique_samples(\n",
    "            device,\n",
    "            all_buys,\n",
    "            all_none_buys,\n",
    "            match_threshold=0.002,\n",
    "            extract_both=False)\n",
    "    print(f'unique samples - buys: {np.shape(unique_buys)} - none buys: {np.shape(all_none_buys)}')\n",
    "    np.savez_compressed(samples_path, buys=unique_buys, none_buys=all_none_buys)\n",
    "\n",
    "samples_file = np.load(samples_path)\n",
    "buy_samples = samples_file['buys']\n",
    "none_buy_samples = samples_file['none_buys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SamplesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, samples):\n",
    "        self._samples = samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._samples)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if (index >= len(self._samples)):\n",
    "            raise IndexError()\n",
    "        sample = np.array([self._samples[index]], dtype=np.float32)\n",
    "        return torch.Tensor(sample).to(device)\n",
    "    \n",
    "    def plot_image(self, index):\n",
    "        img = np.array(self._samples[index])\n",
    "        plt.imshow(img, interpolation='nearest')\n",
    "        data = np.swapaxes(img, 1, 2)\n",
    "        plot_data = {'open': data[0][0], 'high': data[0][1], 'low': data[0][2], 'close': data[0][3]}\n",
    "        df = pd.DataFrame(plot_data)\n",
    "        df.plot(figsize=(10, 5))\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_samples = SamplesDataset(buy_samples)\n",
    "for index in range(3):\n",
    "    buy_samples.plot_image(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_buy_samples = SamplesDataset(none_buy_samples)\n",
    "for index in range(3):\n",
    "    none_buy_samples.plot_image(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_seed(size):\n",
    "    random_data = torch.randn(size).to(device)\n",
    "    return random_data\n",
    "\n",
    "def generate_random_data(size):\n",
    "    random_data = torch.rand(size).to(device)\n",
    "    return random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = [1] + [dimension for dimension in shape]\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.shape[0] = x.shape[0]\n",
    "        return x.view(*self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionHelper:\n",
    "\n",
    "    @classmethod\n",
    "    def calc_2d_size(cls, shape, kernel, stride=(1, 1), padding=(0, 0), dilation=(1, 1)):\n",
    "        return cls._calculate(shape, kernel, stride, padding, dilation, callback=cls.calc_1d_size)\n",
    "\n",
    "    @classmethod\n",
    "    def calc_2d_transpose_size(cls, shape, kernel, stride=(1, 1), padding=(0, 0), dilation=(1, 1)):\n",
    "        return cls._calculate(shape, kernel, stride, padding, dilation, callback=cls.calc_1d_transpose_size)\n",
    "\n",
    "    @classmethod\n",
    "    def _calculate(cls, shape, kernel, stride, padding, dilation, callback):\n",
    "        height = callback(shape[0], kernel[0], stride[0], padding[0], dilation[0])\n",
    "        width = callback(shape[1], kernel[1], stride[1], padding[1], dilation[1])\n",
    "        return height, width\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_1d_size(size, kernel, stride=1, padding=0, dilation=1):\n",
    "        padding *= 2\n",
    "        kernel = dilation * (kernel - 1)\n",
    "        return int(((size + padding - kernel - 1) / stride) + 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_1d_transpose_size(size, kernel, stride=1, padding=0, dilation=1):\n",
    "        padding *= 2\n",
    "        kernel = dilation * (kernel - 1)\n",
    "        return int(((size - 1) * stride) + 1 + kernel - padding)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (5, 4)\n",
    "print(shape)\n",
    "shape = ConvolutionHelper.calc_2d_size(shape=shape, kernel=(2, 2), stride=(1, 1), padding=(0, 0))\n",
    "print(shape)\n",
    "shape = ConvolutionHelper.calc_2d_size(shape=shape, kernel=(2, 2), stride=(1, 1), padding=(0, 0))\n",
    "print(shape)\n",
    "print(shape)\n",
    "shape = ConvolutionHelper.calc_2d_transpose_size(shape=shape, kernel=(2, 2), stride=(1, 1), padding=(0, 0))\n",
    "print(shape)\n",
    "shape = ConvolutionHelper.calc_2d_transpose_size(shape=shape, kernel=(2, 2), stride=(1, 1), padding=(0, 0))\n",
    "print(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        channel = 1\n",
    "        days = 5\n",
    "        values = 4\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(channel, 30, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm2d(30),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            nn.Conv2d(30, 30, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            View([30 * 3 * 2]),\n",
    "            nn.Linear(30 * 3 * 2, channel),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.loss_function = nn.BCELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        self.counter = 0;\n",
    "        self.progress = []\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return self.model(inputs)\n",
    "\n",
    "    def train_net(self, inputs, targets):\n",
    "        outputs = self.forward(inputs)\n",
    "        loss = self.loss_function(outputs, targets)\n",
    "        self.counter += 1;\n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss.item())\n",
    "        if (self.counter % 1000 == 0):\n",
    "            print(\"counter = \", self.counter)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def plot_progress(self):\n",
    "        df = pd.DataFrame(self.progress, columns=['loss'])\n",
    "        df.plot(ylim=(0), figsize=(16,8), alpha=0.3, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# test discriminator can separate real data from random noise\n",
    "\n",
    "D = Discriminator()\n",
    "D.train()\n",
    "# move model to cuda device\n",
    "D.to(device)\n",
    "\n",
    "positive = torch.Tensor([[1.0]]).to(device)\n",
    "negative = torch.Tensor([[0.0]]).to(device)\n",
    "\n",
    "for sample in none_buy_samples:\n",
    "    # real data\n",
    "    D.train_net(sample, positive)\n",
    "    # fake data\n",
    "    D.train_net(generate_random_data((1, 1, 5, 4)), negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.eval()\n",
    "for i in range(4):\n",
    "    sample_tensor = buy_samples[random.randint(0, len(buy_samples))]\n",
    "    print(D.forward(sample_tensor).item())\n",
    "\n",
    "for i in range(4):\n",
    "    print(D.forward(generate_random_data((1, 1, 5, 4))).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        channel = 1\n",
    "        days = 5\n",
    "        values = 4\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 30 * 3 * 2),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            View([30, 3, 2]),\n",
    "            \n",
    "            nn.ConvTranspose2d(30, 30, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm2d(30),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(30, 1, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm2d(1),\n",
    "\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        self.counter = 0;\n",
    "        self.progress = []\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return self.model(inputs)\n",
    "\n",
    "    def train_net(self, D, fake, targets):\n",
    "        d_output = D.forward(fake)\n",
    "        loss = D.loss_function(d_output, targets)\n",
    "        self.counter += 1;\n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss.item())\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def plot_progress(self):\n",
    "        df = pd.DataFrame(self.progress, columns=['loss'])\n",
    "        df.plot(ylim=(0), figsize=(16,8), alpha=0.3, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n",
    "G.to(device)\n",
    "output = G.forward(generate_random_seed((1, 100)))\n",
    "img = output.detach().cpu().numpy()[0]\n",
    "plt.imshow(img, interpolation='nearest')\n",
    "data = np.swapaxes(img, 1, 2)\n",
    "plot_data = {'open': data[0][0], 'high': data[0][1], 'low': data[0][2], 'close': data[0][3]}\n",
    "df = pd.DataFrame(plot_data)\n",
    "df.plot(figsize=(10, 5))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-glucose",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "positive = torch.FloatTensor([[1.0]]).to(device)\n",
    "negative = torch.FloatTensor([[0.0]]).to(device)\n",
    "\n",
    "D = Discriminator()\n",
    "D.train()\n",
    "D.to(device)\n",
    "\n",
    "G = Generator()\n",
    "G.train()\n",
    "G.to(device)\n",
    "\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print (\"fake epoch = \", epoch + 1)\n",
    "    for sample in buy_samples:\n",
    "        # get seed\n",
    "        seed = generate_random_seed((1, 100))\n",
    "        # train discriminator on true\n",
    "        D.train_net(sample, positive)\n",
    "        # train discriminator on false\n",
    "        fake = G.forward(seed)\n",
    "        # train generator\n",
    "        G.train_net(D, fake, positive)\n",
    "        # use detach() so gradients in G are not calculated\n",
    "        D.train_net(fake.detach(), negative)\n",
    "\n",
    "epochs = 2\n",
    "index = 0\n",
    "for epoch in range(epochs):\n",
    "    print (\"real epoch = \", epoch + 1)\n",
    "    for none_sample in none_buy_samples:\n",
    "        sample = buy_samples[index % len(buy_samples)]\n",
    "        D.train_net(sample, positive)\n",
    "        D.train_net(none_sample, negative)\n",
    "        index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-oliver",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_charts = 9\n",
    "columns = int(max_charts**0.5)\n",
    "rows = columns + (1 if max_charts % columns > 0 else 0)\n",
    "f, axarr = plt.subplots(rows, columns, figsize=(20, 20))\n",
    "for index in range(max_charts):\n",
    "    output = G.forward(generate_random_seed((1, 100)))\n",
    "    img = output.detach().cpu().numpy()[0]\n",
    "    data = np.swapaxes(img, 1, 2)\n",
    "    plot_data = {'open': data[0][0], 'high': data[0][1], 'low': data[0][2], 'close': data[0][3]}\n",
    "    df = pd.DataFrame(plot_data)\n",
    "    df.plot(ax=axarr[int(index / columns), index % columns])\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_capital = 1_000.0\n",
    "total = 0.0\n",
    "D.eval()\n",
    "pcts = []\n",
    "columns = ['open', 'high', 'low', 'close']\n",
    "for ticker in provider.tickers:\n",
    "    capital = start_capital\n",
    "    quotes = provider.load(ticker, test_start_date, test_end_date)\n",
    "    if quotes is None:\n",
    "        continue\n",
    "    quotes['window'] = \\\n",
    "        DataPreparator.calculate_windows(\n",
    "            quotes,\n",
    "            days=days,\n",
    "            normalize=True,\n",
    "            columns=columns,\n",
    "            adjust=provider.adjust_prices)\n",
    "    buy_price = 0.0\n",
    "    sell_price = 0.0\n",
    "    stock_count = 0\n",
    "    hold_days = 0\n",
    "    for index, row in quotes[days - 1:-1].iterrows():\n",
    "        if stock_count > 0:\n",
    "#             if hold_days < 10 and sell_price < buy_price:\n",
    "#                 hold_days += 1\n",
    "#                 continue\n",
    "            capital -= 1.0\n",
    "            sell_price = row['adj_close']\n",
    "            result = ((sell_price - buy_price) * stock_count)\n",
    "#             result = ((buy_price - sell_price) * stock_count)\n",
    "            pct = ((sell_price / buy_price) - 1.0) * 100.0\n",
    "            pcts.append(pct)\n",
    "            tax = 0.0\n",
    "            if result > 0.0:\n",
    "                tax = result * (0.25 * 1.055)\n",
    "            capital += (sell_price * stock_count) - tax\n",
    "#             capital += result - tax\n",
    "            buy_price = 0.0\n",
    "            stock_count = 0\n",
    "            hold_days = 0\n",
    "            continue\n",
    "        if stock_count == 0 and D.forward(torch.Tensor([row['window']]).to(device)).item() >= 0.9:\n",
    "            capital -= 1.0\n",
    "            buy_price = row['adj_close']\n",
    "            stock_count = int(capital / buy_price)\n",
    "            capital -= stock_count * buy_price\n",
    "            sell_price = 0.0\n",
    "            hold_days = 0\n",
    "            continue\n",
    "    print(f'{ticker}: {capital:.2f}')\n",
    "    total += capital - start_capital\n",
    "#     break\n",
    "\n",
    "df = pd.DataFrame({'pct': pcts})\n",
    "df['pct'].plot.hist(bins=100)\n",
    "plt.show()\n",
    "plt.close()\n",
    "    \n",
    "print(f'Stocks: {len(provider.tickers)} - Total returns: $ {total:.2f} - Mean returns: $ {total / len(provider.tickers):.2f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-accuracy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
