{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from app.environment.dataprovider import DataProvider\n",
    "from app.preparation.preparator import DataPreparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"using cuda:\", torch.cuda.get_device_name(0))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = os.getenv('TIINGO_API_KEY')\n",
    "days = 5\n",
    "\n",
    "train_start_date = '2000-01-01'\n",
    "train_end_date = '2015-12-31'\n",
    "\n",
    "test_start_date = '2016-01-01'\n",
    "test_end_date = '2020-12-31'\n",
    "\n",
    "provider = DataProvider(apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_buys = None\n",
    "all_none_buys = None\n",
    "columns = ['open', 'high', 'low', 'close']\n",
    "samples_path = f'data/eod/{train_start_date}.{train_end_date}/samples.npz'\n",
    "\n",
    "if not os.path.exists(samples_path):\n",
    "    tickers = provider.tickers.keys()\n",
    "    for ticker in tickers:\n",
    "        company = provider.tickers[ticker]\n",
    "        quotes = provider.load(ticker, train_start_date, train_end_date)\n",
    "        if quotes is None:\n",
    "            continue\n",
    "        quotes[['buy', 'sell']] = DataPreparator.calculate_signals(quotes)\n",
    "        quotes['window'] = \\\n",
    "            DataPreparator.calculate_windows_with_range(\n",
    "                quotes,\n",
    "                days=days,\n",
    "                normalize=True,\n",
    "                columns=columns,\n",
    "                adjust=provider.adjust_prices)\n",
    "        buys = DataPreparator.filter_windows_by_signal(quotes, days, 'buy', 'window')\n",
    "        none_buys = DataPreparator.filter_windows_without_signal(quotes, days, ignore_signals=['buy'])\n",
    "        print(f'{ticker:5} - {company:40} - buys: {np.shape(buys)} - non buys: {np.shape(none_buys)}')\n",
    "        if len(buys) > 0:\n",
    "            all_buys = buys if all_buys is None else np.concatenate((all_buys, buys))\n",
    "        if len(none_buys) > 0:\n",
    "            all_none_buys = none_buys if all_none_buys is None else np.concatenate((all_none_buys, none_buys))\n",
    "    print(f'samples - buys: {np.shape(all_buys)} - none buys: {np.shape(all_none_buys)}')\n",
    "    unique_buys, _ = \\\n",
    "        DataPreparator.extract_unique_samples(\n",
    "            device,\n",
    "            all_buys,\n",
    "            all_none_buys,\n",
    "            match_threshold=0.002,\n",
    "            extract_both=False)\n",
    "    print(f'unique samples - buys: {np.shape(unique_buys)} - none buys: {np.shape(all_none_buys)}')\n",
    "    np.savez_compressed(samples_path, buys=unique_buys, none_buys=all_none_buys)\n",
    "\n",
    "samples_file = np.load(samples_path)\n",
    "buy_sample_data = samples_file['buys']\n",
    "none_buy_sample_data = samples_file['none_buys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SamplesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, samples):\n",
    "        self._samples = samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._samples)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if (index >= len(self._samples)):\n",
    "            raise IndexError()\n",
    "        sample = np.array([self._samples[index]], dtype=np.float32)\n",
    "        return torch.Tensor(sample).to(device)\n",
    "    \n",
    "    def get_batch(self, index, count):\n",
    "        if (index >= len(self._samples)):\n",
    "            raise IndexError()\n",
    "        count = count + index if count + index < len(self._samples) else len(self._samples) - index\n",
    "        samples = np.array(self._samples[index: count], dtype=np.float32)\n",
    "        tensor = torch.Tensor(samples)\n",
    "        return tensor.to(device)\n",
    "        \n",
    "    def plot_image(self, index):\n",
    "        img = np.array(self._samples[index])\n",
    "        img = img.reshape((1, 5, 4))\n",
    "        plt.imshow(img, interpolation='nearest')\n",
    "        data = np.swapaxes(img, 1, 2)\n",
    "        plot_data = {'open': data[0][0], 'high': data[0][1], 'low': data[0][2], 'close': data[0][3]}\n",
    "        df = pd.DataFrame(plot_data)\n",
    "        df.plot(figsize=(10, 5))\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_samples = SamplesDataset(buy_sample_data)\n",
    "for index in range(3):\n",
    "    buy_samples.plot_image(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_buy_samples = SamplesDataset(none_buy_sample_data)\n",
    "for index in range(3):\n",
    "    none_buy_samples.plot_image(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = [1] + [dimension for dimension in shape]\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.shape[0] = x.shape[0]\n",
    "        return x.view(*self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionHelper:\n",
    "\n",
    "    @classmethod\n",
    "    def calc_2d_size(cls, shape, kernel, stride=(1, 1), padding=(0, 0), dilation=(1, 1)):\n",
    "        return cls._calculate(shape, kernel, stride, padding, dilation, callback=cls.calc_1d_size)\n",
    "\n",
    "    @classmethod\n",
    "    def calc_2d_transpose_size(cls, shape, kernel, stride=(1, 1), padding=(0, 0), dilation=(1, 1)):\n",
    "        return cls._calculate(shape, kernel, stride, padding, dilation, callback=cls.calc_1d_transpose_size)\n",
    "\n",
    "    @classmethod\n",
    "    def _calculate(cls, shape, kernel, stride, padding, dilation, callback):\n",
    "        height = callback(shape[0], kernel[0], stride[0], padding[0], dilation[0])\n",
    "        width = callback(shape[1], kernel[1], stride[1], padding[1], dilation[1])\n",
    "        return height, width\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_1d_size(size, kernel, stride=1, padding=0, dilation=1):\n",
    "        padding *= 2\n",
    "        kernel = dilation * (kernel - 1)\n",
    "        return int(((size + padding - kernel - 1) / stride) + 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_1d_transpose_size(size, kernel, stride=1, padding=0, dilation=1):\n",
    "        padding *= 2\n",
    "        kernel = dilation * (kernel - 1)\n",
    "        return int(((size - 1) * stride) + 1 + kernel - padding)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (5, 4)\n",
    "print(shape)\n",
    "shape = ConvolutionHelper.calc_2d_size(shape=shape, kernel=(2, 2), stride=(1, 1), padding=(0, 0))\n",
    "print(shape)\n",
    "shape = ConvolutionHelper.calc_2d_size(shape=shape, kernel=(2, 2), stride=(1, 1), padding=(0, 0))\n",
    "print(shape)\n",
    "print(shape)\n",
    "shape = ConvolutionHelper.calc_2d_transpose_size(shape=shape, kernel=(2, 2), stride=(1, 1), padding=(0, 0))\n",
    "print(shape)\n",
    "shape = ConvolutionHelper.calc_2d_transpose_size(shape=shape, kernel=(2, 2), stride=(1, 1), padding=(0, 0))\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 30, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm2d(30),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            nn.Conv2d(30, 30, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            View([30 * 2 * 3]),\n",
    "            nn.Linear(30 * 2 * 3, 10),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(10, 30 * 2 * 3),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            View([30, 2, 3]),\n",
    "            \n",
    "            nn.ConvTranspose2d(30, 30, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm2d(30),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(30, 1, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm2d(1),\n",
    "\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        self.counter = 0;\n",
    "        self.progress = []\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def train_net(self, inputs, targets):\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_function(outputs, targets)\n",
    "        self.counter += 1;\n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss.item())\n",
    "#         if (self.counter % 1000 == 0):\n",
    "#             print(\"counter = \", self.counter)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def plot_progress(self):\n",
    "        df = pd.DataFrame(self.progress, columns=['loss'])\n",
    "        df.plot(ylim=(0), figsize=(16,8), alpha=0.3, marker='.', grid=True, yticks=(0, 0.025, 0.05, 0.1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# origin sample:\n",
    "######################################################################\n",
    "    \n",
    "sample = none_buy_samples[0]\n",
    "img = sample.detach().cpu().numpy()[0]\n",
    "img = np.swapaxes(img, 1, 2)\n",
    "plt.imshow(img, interpolation='nearest')\n",
    "data = np.swapaxes(img, 1, 2)\n",
    "plot_data = {'open': data[0][0], 'high': data[0][1], 'low': data[0][2], 'close': data[0][3]}\n",
    "df = pd.DataFrame(plot_data)\n",
    "df.plot(figsize=(10, 5))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "######################################################################\n",
    "# decoded sample:\n",
    "######################################################################\n",
    "\n",
    "ae = AutoEncoder()\n",
    "ae.to(device)\n",
    "\n",
    "output = ae.forward(sample)\n",
    "img = output.detach().cpu().numpy()[0]\n",
    "img = np.swapaxes(img, 1, 2)\n",
    "plt.imshow(img, interpolation='nearest')\n",
    "data = np.swapaxes(img, 1, 2)\n",
    "plot_data = {'open': data[0][0], 'high': data[0][1], 'low': data[0][2], 'close': data[0][3]}\n",
    "df = pd.DataFrame(plot_data)\n",
    "df.plot(figsize=(10, 5))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def create_and_train_auto_encoder():\n",
    "    ae = AutoEncoder()\n",
    "    ae.train()\n",
    "    ae.to(device)\n",
    "    batch_size = 1000\n",
    "    epochs = 200\n",
    "    index = 0\n",
    "    for epoch in range(epochs):\n",
    "        print (\"epoch = \", epoch + 1)\n",
    "        for index in range(0, len(none_buy_samples), batch_size):\n",
    "            batch = none_buy_samples.get_batch(index, batch_size)\n",
    "            ae.train_net(batch, batch)\n",
    "    return ae\n",
    "\n",
    "ae = create_and_train_auto_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-rapid",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ae.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.eval()\n",
    "sample = buy_samples[11]\n",
    "output = ae(sample)\n",
    "f, axarr = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "######################################################################\n",
    "# origin sample:\n",
    "######################################################################\n",
    "    \n",
    "orig_img = sample.detach().cpu().numpy()[0]\n",
    "orig_plot_data = {'open': orig_img[0][0], 'high': orig_img[0][1], 'low': orig_img[0][2], 'close': orig_img[0][3]}\n",
    "orig_df = pd.DataFrame(orig_plot_data)\n",
    "orig_df.plot(ax=axarr[0], title='original')\n",
    "\n",
    "######################################################################\n",
    "# decoded sample:\n",
    "######################################################################\n",
    "\n",
    "dec_img = output.detach().cpu().numpy()[0]\n",
    "dec_plot_data = {'open': dec_img[0][0], 'high': dec_img[0][1], 'low': dec_img[0][2], 'close': dec_img[0][3]}\n",
    "dec_df = pd.DataFrame(dec_plot_data)\n",
    "dec_df.plot(ax=axarr[1], title='decoded')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Conv2d(2, 30, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm2d(30),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            nn.Conv2d(30, 30, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            View([30 * 2 * 3]),\n",
    "            nn.Linear(30 * 2 * 3, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.loss_function = nn.BCELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        self.counter = 0;\n",
    "        self.progress = []\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return self.discriminator(inputs)\n",
    "\n",
    "    def train_net(self, auto_encoder, inputs, targets):\n",
    "        decoded = auto_encoder(inputs)\n",
    "        features = torch.cat([inputs, decoded], dim=1)\n",
    "        outputs = self(features.detach())\n",
    "        loss = self.loss_function(outputs, targets)\n",
    "        self.counter += 1;\n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss.item())\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def plot_progress(self):\n",
    "        df = pd.DataFrame(self.progress, columns=['loss'])\n",
    "        df.plot(ylim=(0), figsize=(16,8), alpha=0.3, marker='.', grid=True, yticks=(0, 0.025, 0.05, 0.1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_data(size):\n",
    "    random_data = torch.rand(size).to(device)\n",
    "    return random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator()\n",
    "D.to(device)\n",
    "\n",
    "batch_size = 1000\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    print(f'epoch = {epoch + 1}')\n",
    "    for index in range(0, len(none_buy_samples), batch_size):\n",
    "        none_samples = none_buy_samples.get_batch(index, batch_size)\n",
    "        none_targets = torch.FloatTensor(np.array([0.0] * none_samples.shape[0]).reshape((none_samples.shape[0], 1))).to(device)\n",
    "\n",
    "        fake_samples = generate_random_data((none_samples.shape[0], 1, 4, 5))\n",
    "        fake_targets = torch.FloatTensor(np.array([1.0] * none_samples.shape[0]).reshape((none_samples.shape[0], 1))).to(device)\n",
    "\n",
    "        features = torch.cat([none_samples, fake_samples], dim=0)\n",
    "        targets = torch.cat([none_targets, fake_targets], dim=0)\n",
    "\n",
    "        random = torch.randperm(len(features))\n",
    "        features = features[random]\n",
    "        targets = targets[random]\n",
    "\n",
    "        D.train_net(ae, features, targets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def create_and_train_discriminator():\n",
    "    D = Discriminator()\n",
    "    D.to(device)\n",
    "\n",
    "    batch_size = 5000\n",
    "    epochs = 50\n",
    "\n",
    "    normal_samples = none_buy_samples.get_batch(0, len(none_buy_samples)).cpu()\n",
    "    normal_targets = torch.FloatTensor(np.array([0.0] * normal_samples.shape[0]).reshape((normal_samples.shape[0], 1)))\n",
    "\n",
    "    signal_samples = buy_samples.get_batch(0, len(buy_samples)).cpu()\n",
    "    count = int(normal_samples.shape[0] / signal_samples.shape[0])\n",
    "    for _ in range(count):\n",
    "        signal_samples = torch.cat([signal_samples, buy_samples.get_batch(0, len(buy_samples)).cpu()], dim=0)\n",
    "    signal_targets = torch.FloatTensor(np.array([1.0] * signal_samples.shape[0]).reshape((signal_samples.shape[0], 1)))\n",
    "\n",
    "    features = torch.cat([normal_samples, signal_samples], dim=0)\n",
    "    targets = torch.cat([normal_targets, signal_targets], dim=0)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'epoch = {epoch + 1}')\n",
    "        random = torch.randperm(len(features))\n",
    "        features = features[random]\n",
    "        targets = targets[random]\n",
    "        for index in range(0, len(features), batch_size):\n",
    "            count = index + batch_size if index + batch_size < len(features) else len(features) - index\n",
    "            D.train_net(ae, features[index: count].to(device), targets[index: count].to(device))\n",
    "    return D\n",
    "\n",
    "D = create_and_train_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-headquarters",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trader(nn.Module):\n",
    "    \n",
    "    def __init__(self, auto_encoder, discriminator):\n",
    "        super(Trader, self).__init__()\n",
    "        self.auto_encoder = auto_encoder\n",
    "        self.discriminator = discriminator\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        decoded = self.auto_encoder(inputs)\n",
    "        features = torch.cat([inputs, decoded], dim=1)\n",
    "        outputs = self.discriminator(features)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "trader = Trader(ae, D)\n",
    "ae.eval()\n",
    "D.eval()\n",
    "trader.eval()\n",
    "\n",
    "filtered_samples_path = f'data/eod/{train_start_date}.{train_end_date}/filtered_samples.npz'\n",
    "\n",
    "if not os.path.exists(filtered_samples_path):\n",
    "    all_buy_samples = None\n",
    "    all_none_buy_samples = None\n",
    "    columns = ['open', 'high', 'low', 'close']\n",
    "    tickers = provider.tickers.keys()\n",
    "    for ticker in tickers:\n",
    "        company = provider.tickers[ticker]\n",
    "        quotes = provider.load(ticker, train_start_date, train_end_date)\n",
    "        if quotes is None:\n",
    "            continue\n",
    "        quotes['window'] = \\\n",
    "            DataPreparator.calculate_windows_with_range(\n",
    "                quotes,\n",
    "                days=days,\n",
    "                normalize=True,\n",
    "                columns=columns,\n",
    "                adjust=provider.adjust_prices)\n",
    "        quotes['next_change'] = ((quotes['adj_close'].shift(-1) / quotes['adj_close']) - 1.0) * 100.0\n",
    "        windows = np.array(quotes[days - 1:-1]['window'].values.tolist(), dtype=np.float32)\n",
    "        next_changes = np.array(quotes[days - 1:-1]['next_change'].values.tolist(), dtype=np.float32)\n",
    "        windows = windows.reshape((windows.shape[0], 1, windows.shape[-2], windows.shape[-1]))\n",
    "        result = trader(torch.Tensor(windows).to(device)).detach().cpu().numpy().flatten()\n",
    "        data = np.array([result, next_changes], np.float32)\n",
    "\n",
    "        detected_windows = np.where((data[0] >= 0.9) & (data[1] >= 1.0))\n",
    "        buy_samples = windows[detected_windows[0]]\n",
    "        all_buy_samples = (buy_samples\n",
    "                           if all_buy_samples is None\n",
    "                           else np.concatenate([all_buy_samples, buy_samples], axis=0))\n",
    "\n",
    "        detected_windows = np.where((data[0] < 0.9) | (data[1] < 1.0))\n",
    "        none_buy_samples = windows[detected_windows[0]]\n",
    "        all_none_buy_samples = (none_buy_samples \n",
    "                                if all_none_buy_samples is None \n",
    "                                else np.concatenate([all_none_buy_samples, none_buy_samples], axis=0))\n",
    "        print(f'{ticker} - {company} - buys: {np.shape(buy_samples)} - none buys: {np.shape(none_buy_samples)}')\n",
    "        \n",
    "    print(f'filtered samples - buys: {np.shape(all_buy_samples)} - none buys: {np.shape(all_none_buy_samples)}')\n",
    "    np.savez_compressed(filtered_samples_path, buys=all_buy_samples, none_buys=all_none_buy_samples)\n",
    "\n",
    "samples_file = np.load(filtered_samples_path)\n",
    "buy_sample_data = samples_file['buys']\n",
    "none_buy_sample_data = samples_file['none_buys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_samples = SamplesDataset(buy_sample_data)\n",
    "for index in range(3):\n",
    "    buy_samples.plot_image(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_buy_samples = SamplesDataset(none_buy_sample_data)\n",
    "for index in range(3):\n",
    "    none_buy_samples.plot_image(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('create and train auto encoder ...')\n",
    "ae = create_and_train_auto_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('create and train discriminator ...')\n",
    "D = create_and_train_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.eval()\n",
    "D.eval()\n",
    "trader = Trader(ae, D)\n",
    "trader.eval()\n",
    "\n",
    "start_capital = 100_000.0\n",
    "total = 0.0\n",
    "pcts = []\n",
    "columns = ['open', 'high', 'low', 'close']\n",
    "tickers = ['ATVI', 'ADBE', 'GOOGL', 'AMZN', 'AXP', 'AAPL', 'CHD', 'DOW', 'FB', 'IBM', 'JPM', 'KEY', 'KLAC',\n",
    "           'MSFT', 'PYPL', 'RMD', 'SLB', 'SNAP', 'VRSN', 'V', 'DIS', 'ZNGA']\n",
    "for ticker in tickers:\n",
    "# for ticker in provider.tickers:\n",
    "    capital = start_capital\n",
    "    quotes = provider.load(ticker, test_start_date, test_end_date)\n",
    "    if quotes is None:\n",
    "        continue\n",
    "    quotes['window'] = \\\n",
    "        DataPreparator.calculate_windows_with_range(\n",
    "            quotes,\n",
    "            days=days,\n",
    "            normalize=True,\n",
    "            columns=columns,\n",
    "            adjust=provider.adjust_prices)\n",
    "    buy_price = 0.0\n",
    "    sell_price = 0.0\n",
    "    stock_count = 0\n",
    "    hold_days = 0\n",
    "    for index, row in quotes[days - 1:-1].iterrows():\n",
    "        if stock_count > 0:\n",
    "#             if hold_days < 5:\n",
    "#                 hold_days += 1\n",
    "#                 continue\n",
    "            capital -= 1.0\n",
    "            sell_price = row['adj_close']\n",
    "            result = ((sell_price - buy_price) * stock_count)\n",
    "            pct = ((sell_price / buy_price) - 1.0) * 100.0\n",
    "            pcts.append(pct)\n",
    "            tax = 0.0\n",
    "            if result > 0.0:\n",
    "                tax = result * (0.25 * 1.055)\n",
    "            capital += (sell_price * stock_count) - tax\n",
    "            buy_price = 0.0\n",
    "            stock_count = 0\n",
    "            hold_days = 0\n",
    "            continue\n",
    "        result = trader(torch.Tensor([row['window']]).to(device)).item()\n",
    "        if stock_count == 0 and result >= 0.925:\n",
    "            capital -= 1.0\n",
    "            buy_price = row['adj_close']\n",
    "            stock_count = int(capital / buy_price)\n",
    "            capital -= stock_count * buy_price\n",
    "            sell_price = 0.0\n",
    "            hold_days = 0\n",
    "            continue\n",
    "    print(f'{ticker}: {capital:.2f}')\n",
    "    total += capital - start_capital\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'pct': pcts})\n",
    "df['pct'].plot.hist(bins=100)\n",
    "plt.show()\n",
    "plt.close()\n",
    "    \n",
    "print(f'Stocks: {len(provider.tickers)} - Total returns: $ {total:.2f} - Mean returns: $ {total / len(provider.tickers):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-blake",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
