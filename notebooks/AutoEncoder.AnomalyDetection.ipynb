{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from app.environment.dataprovider import DataProvider\n",
    "from app.preparation.preparator import DataPreparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"using cuda:\", torch.cuda.get_device_name(0))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = os.getenv('TIINGO_API_KEY')\n",
    "days = 5\n",
    "ticker = 'MSFT'\n",
    "\n",
    "train_start_date = '2000-01-01'\n",
    "train_end_date = '2015-12-31'\n",
    "\n",
    "test_start_date = '2016-01-01'\n",
    "test_end_date = '2020-12-31'\n",
    "\n",
    "provider = DataProvider(apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "all_buys = None\n",
    "all_none_buys = None\n",
    "columns = ['open', 'high', 'low', 'close']\n",
    "file_name = f'{ticker}.npz' if ticker is not None else 'all_tickers.npz'\n",
    "all_data_path = f'data/eod/{train_start_date}.{train_end_date}/{file_name}'\n",
    "tickers = [ticker] if ticker is not None else provider.tickers.keys()\n",
    "\n",
    "if not os.path.exists(all_data_path):\n",
    "    all_windows = None\n",
    "    all_next_changes = None\n",
    "    for ticker in tickers:\n",
    "        company = provider.tickers[ticker]\n",
    "        quotes = provider.load(ticker, train_start_date, train_end_date)\n",
    "        if quotes is None:\n",
    "            print(f'{ticker} - {company} missing data ...')\n",
    "            continue\n",
    "        print(f'{ticker} - {company} loading ...')\n",
    "        quotes['next_change'] = ((quotes['adj_close'].shift(-1) / quotes['adj_close']) - 1.0) * 100.0\n",
    "        quotes['window'] = \\\n",
    "            DataPreparator.calculate_windows_with_range(\n",
    "                quotes,\n",
    "                days=days,\n",
    "                normalize=True,\n",
    "                columns=columns,\n",
    "                adjust=provider.adjust_prices)\n",
    "        windows = np.array(quotes['window'].values.tolist())\n",
    "        next_changes = quotes['next_change'].values\n",
    "        all_windows = windows if all_windows is None else np.concatenate([all_windows, windows], axis=0)\n",
    "        all_next_changes = next_changes if all_next_changes is None else np.concatenate([all_next_changes, next_changes], axis=0)\n",
    "        \n",
    "    np.savez_compressed(all_data_path, windows=all_windows, next_changes=all_next_changes)\n",
    "\n",
    "all_data_file = np.load(all_data_path)\n",
    "windows_data = all_data_file['windows'][days - 1:]\n",
    "next_changes_data = all_data_file['next_changes'][days - 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SamplesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, windows, next_changes):\n",
    "        self._windows = windows\n",
    "        self._next_changes = next_changes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._windows)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if (index >= len(self._windows)):\n",
    "            raise IndexError()\n",
    "        window = np.array([self._windows[index]], dtype=np.float32)\n",
    "        next_change = np.array([self._next_changes[index]], dtype=np.float32)\n",
    "        return torch.Tensor(window).to(device), torch.Tensor(next_change).to(device)\n",
    "    \n",
    "    def get_batch(self, index, count):\n",
    "        if (index >= len(self._windows)):\n",
    "            raise IndexError()\n",
    "        count = count + index if count + index < len(self._windows) else len(self._windows) - index\n",
    "        windows = np.array(self._windows[index: count], dtype=np.float32)\n",
    "        next_changes = np.array(self._next_changes[index: count], dtype=np.float32)\n",
    "        return torch.Tensor(windows).to(device), torch.Tensor(next_changes).to(device)\n",
    "        \n",
    "    def plot_image(self, index):\n",
    "        img = np.array(self._windows[index])\n",
    "        img = img.reshape((1, 5, 4))\n",
    "        plt.imshow(img, interpolation='nearest')\n",
    "        data = np.swapaxes(img, 1, 2)\n",
    "        plot_data = {'open': data[0][0], 'high': data[0][1], 'low': data[0][2], 'close': data[0][3]}\n",
    "        df = pd.DataFrame(plot_data)\n",
    "        df.plot(figsize=(10, 5))\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = SamplesDataset(windows_data, next_changes_data)\n",
    "for index in range(4, 7):\n",
    "    samples.plot_image(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = [1] + [dimension for dimension in shape]\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.shape[0] = x.shape[0]\n",
    "        return x.view(*self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionHelper:\n",
    "\n",
    "    @classmethod\n",
    "    def calc_2d_size(cls, shape, kernel, stride=(1, 1), padding=(0, 0), dilation=(1, 1)):\n",
    "        return cls._calculate(shape, kernel, stride, padding, dilation, callback=cls.calc_1d_size)\n",
    "\n",
    "    @classmethod\n",
    "    def calc_2d_transpose_size(cls, shape, kernel, stride=(1, 1), padding=(0, 0), dilation=(1, 1)):\n",
    "        return cls._calculate(shape, kernel, stride, padding, dilation, callback=cls.calc_1d_transpose_size)\n",
    "\n",
    "    @classmethod\n",
    "    def _calculate(cls, shape, kernel, stride, padding, dilation, callback):\n",
    "        height = callback(shape[0], kernel[0], stride[0], padding[0], dilation[0])\n",
    "        width = callback(shape[1], kernel[1], stride[1], padding[1], dilation[1])\n",
    "        return height, width\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_1d_size(size, kernel, stride=1, padding=0, dilation=1):\n",
    "        padding *= 2\n",
    "        kernel = dilation * (kernel - 1)\n",
    "        return int(((size + padding - kernel - 1) / stride) + 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_1d_transpose_size(size, kernel, stride=1, padding=0, dilation=1):\n",
    "        padding *= 2\n",
    "        kernel = dilation * (kernel - 1)\n",
    "        return int(((size - 1) * stride) + 1 + kernel - padding)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (5, 4)\n",
    "print(shape)\n",
    "shape = ConvolutionHelper.calc_2d_size(shape=shape, kernel=(2, 2), stride=(1, 1), padding=(0, 0))\n",
    "print(shape)\n",
    "shape = ConvolutionHelper.calc_2d_size(shape=shape, kernel=(2, 2), stride=(1, 1), padding=(0, 0))\n",
    "print(shape)\n",
    "print(shape)\n",
    "shape = ConvolutionHelper.calc_2d_transpose_size(shape=shape, kernel=(2, 2), stride=(1, 1), padding=(0, 0))\n",
    "print(shape)\n",
    "shape = ConvolutionHelper.calc_2d_transpose_size(shape=shape, kernel=(2, 2), stride=(1, 1), padding=(0, 0))\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 30, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm2d(30),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            nn.Conv2d(30, 30, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            View([30 * 2 * 3]),\n",
    "            nn.Linear(30 * 2 * 3, 10),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(10, 30 * 2 * 3),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            View([30, 2, 3]),\n",
    "            \n",
    "            nn.ConvTranspose2d(30, 30, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm2d(30),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(30, 1, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm2d(1),\n",
    "\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        self.counter = 0;\n",
    "        self.progress = []\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def train_net(self, inputs, targets):\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_function(outputs, targets)\n",
    "        self.counter += 1;\n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss.item())\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def plot_progress(self):\n",
    "        df = pd.DataFrame(self.progress, columns=['loss'])\n",
    "        df.plot(ylim=(0), figsize=(16,8), alpha=0.3, marker='.', grid=True, yticks=(0, 0.025, 0.05, 0.1, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# origin sample:\n",
    "######################################################################\n",
    "    \n",
    "sample, _ = samples[4]\n",
    "img = sample.detach().cpu().numpy()[0]\n",
    "img = np.swapaxes(img, 1, 2)\n",
    "plt.imshow(img, interpolation='nearest')\n",
    "data = np.swapaxes(img, 1, 2)\n",
    "plot_data = {'open': data[0][0], 'high': data[0][1], 'low': data[0][2], 'close': data[0][3]}\n",
    "df = pd.DataFrame(plot_data)\n",
    "df.plot(figsize=(10, 5))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "######################################################################\n",
    "# decoded sample:\n",
    "######################################################################\n",
    "\n",
    "auto_encoder = AutoEncoder()\n",
    "auto_encoder.to(device)\n",
    "\n",
    "output = auto_encoder.forward(sample)\n",
    "img = output.detach().cpu().numpy()[0]\n",
    "img = np.swapaxes(img, 1, 2)\n",
    "plt.imshow(img, interpolation='nearest')\n",
    "data = np.swapaxes(img, 1, 2)\n",
    "plot_data = {'open': data[0][0], 'high': data[0][1], 'low': data[0][2], 'close': data[0][3]}\n",
    "df = pd.DataFrame(plot_data)\n",
    "df.plot(figsize=(10, 5))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def create_and_train_auto_encoder():\n",
    "    auto_encoder = AutoEncoder()\n",
    "    auto_encoder.train()\n",
    "    auto_encoder.to(device)\n",
    "    batch_size = 100\n",
    "    epochs = 100\n",
    "    index = 0\n",
    "    for epoch in range(epochs):\n",
    "        print (\"epoch = \", epoch + 1)\n",
    "        for index in range(0, len(samples), batch_size):\n",
    "            batch, _ = samples.get_batch(index, batch_size)\n",
    "            random = torch.randperm(len(batch))\n",
    "            batch = batch[random]\n",
    "            auto_encoder.train_net(batch, batch)\n",
    "    return auto_encoder\n",
    "\n",
    "auto_encoder = create_and_train_auto_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-rapid",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auto_encoder.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encoder.eval()\n",
    "sample, _ = samples[256]\n",
    "output = auto_encoder(sample)\n",
    "f, axarr = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "######################################################################\n",
    "# origin sample:\n",
    "######################################################################\n",
    "    \n",
    "orig_img = sample.detach().cpu().numpy()[0]\n",
    "orig_plot_data = {'open': orig_img[0][0], 'high': orig_img[0][1], 'low': orig_img[0][2], 'close': orig_img[0][3]}\n",
    "orig_df = pd.DataFrame(orig_plot_data)\n",
    "orig_df.plot(ax=axarr[0], title='original')\n",
    "\n",
    "######################################################################\n",
    "# decoded sample:\n",
    "######################################################################\n",
    "\n",
    "dec_img = output.detach().cpu().numpy()[0]\n",
    "dec_plot_data = {'open': dec_img[0][0], 'high': dec_img[0][1], 'low': dec_img[0][2], 'close': dec_img[0][3]}\n",
    "dec_df = pd.DataFrame(dec_plot_data)\n",
    "dec_df.plot(ax=axarr[1], title='decoded')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Conv2d(2, 30, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm2d(30),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            nn.Conv2d(30, 30, kernel_size=2, stride=1),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            View([30 * 2 * 3]),\n",
    "            nn.Linear(30 * 2 * 3, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.loss_function = nn.BCELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        self.counter = 0;\n",
    "        self.progress = []\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return self.discriminator(inputs)\n",
    "\n",
    "    def train_net(self, auto_encoder, inputs, targets):\n",
    "        decoded = auto_encoder(inputs)\n",
    "        diff = torch.sum((torch.sum((decoded - inputs) ** 2, dim=3) ** 0.5), dim=2)\n",
    "        labels = torch.where(diff >= 2.0, 1.0, 0.0)\n",
    "        features = torch.cat([inputs, decoded], dim=1)\n",
    "        outputs = self(features.detach())\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        self.counter += 1;\n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss.item())\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def plot_progress(self):\n",
    "        df = pd.DataFrame(self.progress, columns=['loss'])\n",
    "        df.plot(ylim=(0), figsize=(16,8), alpha=0.3, marker='.', grid=True, yticks=(0, 0.025, 0.05, 0.1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_data(size):\n",
    "    random_data = torch.rand(size).to(device)\n",
    "    return random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "discriminator.to(device)\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    print(f'epoch = {epoch + 1}')\n",
    "    for index in range(0, len(samples), batch_size):\n",
    "        none_samples, _ = samples.get_batch(index, batch_size)\n",
    "        none_targets = torch.FloatTensor(np.array([0.0] * none_samples.shape[0]).reshape((none_samples.shape[0], 1))).to(device)\n",
    "\n",
    "        fake_samples = generate_random_data((none_samples.shape[0], 1, 4, 5))\n",
    "        fake_targets = torch.FloatTensor(np.array([1.0] * none_samples.shape[0]).reshape((none_samples.shape[0], 1))).to(device)\n",
    "\n",
    "        features = torch.cat([none_samples, fake_samples], dim=0)\n",
    "        targets = torch.cat([none_targets, fake_targets], dim=0)\n",
    "\n",
    "        random = torch.randperm(len(features))\n",
    "        features = features[random]\n",
    "        targets = targets[random]\n",
    "\n",
    "        discriminator.train_net(auto_encoder, features, targets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sample(features, labels):\n",
    "    shape = features.shape\n",
    "    features = features.cpu().view((shape[0], shape[1] * shape[2] * shape[3])).numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    features, labels = SMOTE().fit_resample(features, labels)\n",
    "    return torch.Tensor(features).view((features.shape[0], shape[1], shape[2], shape[3])).to(device), torch.Tensor(labels).view((labels.shape[0], 1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "discriminator = Discriminator()\n",
    "discriminator.to(device)\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    print(f'epoch = {epoch + 1}')\n",
    "    for index in range(0, len(samples), batch_size):\n",
    "        features, labels = samples.get_batch(index, batch_size)\n",
    "        if not features.shape[0] > 0:\n",
    "            break\n",
    "        labels = torch.where(labels > 1.0, 1.0, 0.0)\n",
    "\n",
    "        features, labels = over_sample(features, labels)\n",
    "        \n",
    "        random = torch.randperm(len(features))\n",
    "        features = features[random]\n",
    "        labels = labels[random]\n",
    "\n",
    "        discriminator.train_net(auto_encoder, features, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.plot_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trader(nn.Module):\n",
    "    \n",
    "    def __init__(self, auto_encoder, discriminator):\n",
    "        super(Trader, self).__init__()\n",
    "        self.auto_encoder = auto_encoder\n",
    "        self.discriminator = discriminator\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        decoded = self.auto_encoder(inputs)\n",
    "        features = torch.cat([inputs, decoded], dim=1)\n",
    "        outputs = self.discriminator(features)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encoder.eval()\n",
    "discriminator.eval()\n",
    "trader = Trader(auto_encoder, discriminator)\n",
    "trader.eval()\n",
    "\n",
    "start_capital = 10_000.0\n",
    "total = 0.0\n",
    "pcts = []\n",
    "columns = ['open', 'high', 'low', 'close']\n",
    "# tickers = ['ATVI', 'ADBE', 'GOOGL', 'AMZN', 'AXP', 'AAPL', 'CHD', 'DOW', 'FB', 'IBM', 'JPM', 'KEY', 'KLAC',\n",
    "#            'MSFT', 'PYPL', 'RMD', 'SLB', 'SNAP', 'VRSN', 'V', 'DIS', 'ZNGA']\n",
    "tickers = [ticker] if ticker is not None else provider.tickers.keys()\n",
    "for ticker in tickers:\n",
    "    capital = start_capital\n",
    "    quotes = provider.load(ticker, test_start_date, test_end_date)\n",
    "    if quotes is None:\n",
    "        continue\n",
    "    quotes['window'] = \\\n",
    "        DataPreparator.calculate_windows_with_range(\n",
    "            quotes,\n",
    "            days=days,\n",
    "            normalize=True,\n",
    "            columns=columns,\n",
    "            adjust=provider.adjust_prices)\n",
    "    buy_price = 0.0\n",
    "    sell_price = 0.0\n",
    "    stock_count = 0\n",
    "    hold_days = 0\n",
    "    for index, row in quotes[days - 1:-1].iterrows():\n",
    "        if stock_count > 0:\n",
    "#             if hold_days < 20:\n",
    "#                 hold_days += 1\n",
    "#                 continue\n",
    "            capital -= 1.0\n",
    "            sell_price = row['adj_close']\n",
    "            result = ((sell_price - buy_price) * stock_count)\n",
    "            pct = ((sell_price / buy_price) - 1.0) * 100.0\n",
    "            pcts.append(pct)\n",
    "            tax = 0.0\n",
    "            if result > 0.0:\n",
    "                tax = result * (0.25 * 1.055)\n",
    "            capital += (sell_price * stock_count) - tax\n",
    "            buy_price = 0.0\n",
    "            stock_count = 0\n",
    "            hold_days = 0\n",
    "            continue\n",
    "        result = trader(torch.Tensor([row['window']]).to(device)).item()\n",
    "        if stock_count == 0 and result >= 0.95:\n",
    "            capital -= 1.0\n",
    "            buy_price = row['adj_close']\n",
    "            stock_count = int(capital / buy_price)\n",
    "            capital -= stock_count * buy_price\n",
    "            sell_price = 0.0\n",
    "            hold_days = 0\n",
    "            continue\n",
    "    print(f'{ticker}: {capital:.2f}')\n",
    "    total += capital - start_capital\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'pct': pcts})\n",
    "df['pct'].plot.hist(bins=100)\n",
    "plt.show()\n",
    "plt.close()\n",
    "    \n",
    "print(f'Stocks: {len(tickers)} - Total returns: $ {total:.2f} - Mean returns: $ {total / len(tickers):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = []\n",
    "data = {}\n",
    "days_count = 0\n",
    "for ticker, company in provider.tickers.items():\n",
    "    print(f'{company} loading ...')\n",
    "    quotes = provider.load(ticker, test_start_date, test_end_date)\n",
    "    columns = ['open', 'high', 'low', 'close']\n",
    "    quotes['window'] = \\\n",
    "            DataPreparator.calculate_windows_with_range(\n",
    "                quotes,\n",
    "                days=days,\n",
    "                normalize=True,\n",
    "                columns=columns,\n",
    "                adjust=provider.adjust_prices)\n",
    "\n",
    "    features = torch.Tensor(np.array(quotes[days - 1:-1]['window'].values.tolist(), dtype=np.float32)).to(device)\n",
    "    decoded = auto_encoder(features)\n",
    "    diff = torch.sum((torch.sum((decoded - features) ** 2, dim=3) ** 0.5), dim=2).detach().cpu().numpy().flatten()\n",
    "    diff = np.concatenate([np.zeros(len(quotes) - diff.shape[0]), diff])\n",
    "    quotes['diff'] = np.where(diff > 1.5, diff, np.nan)\n",
    "    quotes['lower'] = np.array([np.sum(np.where(window.values < window.values[-1], 1, 0)) for window in quotes['adj_close'].rolling(5)])\n",
    "    quotes['buy'] = np.where((quotes['diff'].values > 0.0) & (quotes['lower'].values > 2), quotes['adj_close'], np.nan) * 1.008\n",
    "    quotes['sell'] = quotes['adj_close']\n",
    "    data[f'{ticker}_buy'] = quotes['buy'].values\n",
    "    data[f'{ticker}_sell'] = quotes['sell'].values\n",
    "    data[f'{ticker}_diff'] = quotes['diff'].values\n",
    "    days_count = days_count if days_count > len(quotes) else len(quotes)\n",
    "\n",
    "tickers = [ticker for ticker in provider.tickers.keys() if f'{ticker}_buy' in data]\n",
    "buy_columns = [f'{ticker}_buy' for ticker in provider.tickers.keys() if f'{ticker}_buy' in data]\n",
    "sell_columns = [f'{ticker}_sell' for ticker in provider.tickers.keys() if f'{ticker}_sell' in data]\n",
    "diff_columns = [f'{ticker}_diff' for ticker in provider.tickers.keys() if f'{ticker}_diff' in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital = 50_000.0\n",
    "\n",
    "def get_value(column, index):\n",
    "    if index >= len(data[column]):\n",
    "        return None\n",
    "    if data[column][index] != data[column][index]:\n",
    "        return None\n",
    "    return data[column][index]\n",
    "\n",
    "def sort_diff(index):\n",
    "    if row[diff_columns[index]] is None:\n",
    "        return 0.0\n",
    "    return row[diff_columns[index]]\n",
    "\n",
    "portfolio = {}\n",
    "position_count = 5\n",
    "for index in range(days_count):\n",
    "    row = {column: get_value(column, index) for column in buy_columns}\n",
    "    row.update({column: get_value(column, index) for column in sell_columns})\n",
    "    row.update({column: get_value(column, index) for column in diff_columns})\n",
    "    sell_tickers = []\n",
    "    for ticker in tickers:\n",
    "        if ticker not in portfolio:\n",
    "            continue\n",
    "        if portfolio[ticker]['day'] >= 19:\n",
    "            if row[f'{ticker}_sell'] is None:\n",
    "                capital += 1.0\n",
    "                capital += portfolio[ticker]['investment']\n",
    "            else:\n",
    "                ratio = ((row[f'{ticker}_sell'] * portfolio[ticker]['count']) / portfolio[ticker]['investment']) - 1.0\n",
    "                if ratio > 0.0:\n",
    "                    ratio *= (1.0 - (0.25 * 1.055))\n",
    "                ratio += 1.0\n",
    "                capital -= 1.0\n",
    "                print(ratio)\n",
    "                capital += portfolio[ticker]['investment'] * ratio\n",
    "            del portfolio[ticker]\n",
    "            sell_tickers.append(ticker)\n",
    "        else:\n",
    "            portfolio[ticker]['day'] += 1\n",
    "\n",
    "    buy_indices = [index for index in range(len(buy_columns)) if row[buy_columns[index]] is not None]\n",
    "#     for column_index in sorted(buy_indices, key=sort_diff, reverse=True):\n",
    "    for column_index in sorted(buy_indices, key=sort_diff, reverse=False):\n",
    "        if len(portfolio) >= position_count:\n",
    "            break\n",
    "        if tickers[column_index] in sell_tickers:\n",
    "            continue\n",
    "        if row[buy_columns[column_index]] is None:\n",
    "            break\n",
    "        if capital - 1.0 < row[buy_columns[column_index]]:\n",
    "            continue\n",
    "        investment = ((capital - 1.0) / (position_count - len(portfolio)))\n",
    "        if not investment > 0.0:\n",
    "            break\n",
    "        count = int(investment / row[buy_columns[column_index]])\n",
    "        if not count > 0:\n",
    "            break\n",
    "        portfolio[tickers[column_index]] = {\n",
    "            'count': count,\n",
    "            'investment': row[buy_columns[column_index]] * count,\n",
    "            'day': 0\n",
    "        }\n",
    "        capital -= 1.0\n",
    "        capital -= portfolio[tickers[column_index]]['investment']\n",
    "        \n",
    "for value in portfolio.values():\n",
    "    capital += 1.0 + value['investment']\n",
    "\n",
    "print(f'{capital:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-jason",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
